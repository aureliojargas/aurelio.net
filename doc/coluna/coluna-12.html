---
date: 2001-11-09
title: "coluna do aurelio 12: lynx (navegação turbinada)"
---

<blockquote>
  "mas afinal, que graça tem ver a internet apenas como texto?" - indagam os incrédulos.
</blockquote>

<p>depende. se você está navegando despreocupadamente, a passeio, e com um link rápido, não tem muita graça mesmo, use o netscape. mas se você está com o tempo curto, fazendo pesquisas na internet e num link lento, para que perder tempo com vários tipos de fonte, tamanhos, cores, formatação desnecessária, imagens gratuitas, banners, flash, shockwave, javascript, e outras novidades tecnológicas inúteis que inventarão?</p>

<p>como trabalhar com o auxílio da internet para obter informações é rotina de muitos, o navegador <code>lynx</code> (<a href="http://lynx.browser.org">http://lynx.browser.org</a>) é uma ferramenta indispensável. para começo de conversa, como bom navegador texto que é, ele nem tenta carregar as imagens da página, ou interpretar javascript, flash e outras "linguagens de programação" similares, mostrando a página mais rápido que qualquer navegador gráfico.</p>

<p>como também não precisa se preocupar com tamanhos, cores e tipos de fontes e desenho de frames e linhas de tabela, o texto é cuspido rapidamente na tela. falando sobre tabelas, versões mais recentes do <code>lynx</code> até fazem algum tratamento nelas, tabulando as colunas, alinhando-as. mas sem desenhar as bordas, continua tudo apenas texto.</p>

<p>este é o grande trunfo do <code>lynx</code> sobre seus "concorrentes", sempre se tem apenas texto na tela, texto este que pode ser gravado num arquivo (comando <code>p</code> - Print) e "grepado" ou editado facilmente.</p>

<p>então para começar, pode-se chamar o programa já indicando a URL:</p>

<pre>
lynx https://aurelio.net
</pre>

<p>ou dentro dele, coloque uma URL nova com o comando <code>g</code> (Go to), ou edite a URL atual com o gê maiúsculo: <code>G</code> (g/G, lembrou do vi?). ah! por falar em <code>grep</code>, para procurar um texto qualquer na página, use a barra <code>/</code>.</p>

<p>a navegação entre links e páginas é feita de forma intuitiva, utilizando as setas <code>-&gt;</code> e <code>&lt;-</code> para ir e voltar. as setas para cima e para baixo servem para escolher os links da página e <code>Page Up/Down</code> servem para rolá-la. para sair, <code>q</code>.</p>

<p>para saciar a curiosidade de quem nunca viu uma página HTML em modo texto, aqui vai um <code>screenshot</code>:</p>

<pre>
                                 Título

   Um parágrafo normal de texto, com uma imagem: [ovni.jpg], seguida de
um   texto
  pré     formatado.

   E agora uma lista de itens e subitens:
 * segunda-feira
 * terça-feira
      + tomar banho
      + pagar contas
           o telefone
           o luz
           o água
 * quarta-feira
 * ...

   E para terminar uma tabelinha de 3 colunas:

   joão manoel              (operador)       manhã/tarde
   josé maria          (manutenção elétrica)       tarde
   jair antônio carlos       (limpeza)             noite

   Obs.: note os alinhamentos esquerda/centralizado/direita
</pre>

<p>como se pode ver, as imagens aparecem apenas com o nome entre colchetes, ou com o conteúdo do campo <code>ALT=""</code>, caso especificado. entrando na tela de opções (comando <code>o</code>), podemos ignorar completamente as imagens, ou mostrá-las como links, para vê-las se quiser.</p>

<p>mas como ver imagens num navegador texto? basta usar um visualizador de imagens externo para console, como o <code>zgv</code> (veja coluna do aurelio #3). o <code>lynx</code> respeita as configurações de <code>mime types</code> e seus programas, então basta adicionar a seguinte linha em seu <code>/etc/mailcap</code>:</p>

<pre>
image/*; /usr/bin/zgv %s
</pre>

<p>e ao seguir um link que aponta para uma imagem, o <code>zgv</code> é chamado para mostrá-la. mas mostrar imagens é uma das últimas coisas que se quer de um navegador texto, então vamos para a parte quente: extração de dados.</p>

<p>reforçando, como visto no exemplo, até as tabelas são representadas apenas com texto, então a extração de informação fica facilitada, não precisando ignorar caracteres embelezadores.</p>

<p>uma tarefa bem comum, é uma extração automatizada de dados à partir de uma página qualquer, digamos, uma que tenha a cotação diária do dólar. lááááá no meio da página, depois de quilos de banners de propaganda e links de navegação do site, tem uma linha assim:</p>

<pre>
Dólar paralelo (08/11/2001): R$ 2,62 compra   R$ 2,67 venda 
</pre>

<p>e precisamos extrair diariamente, as cotações de compra e venda para colocar num documento local. do diariamente, o <code>crontab</code> se encarrega. mas como extrair apenas um trecho de uma página da internet? temos uma opção mágica para que o <code>lynx</code> busque a página, renderize-a e cuspa o texto na saída padrão:</p>

<pre>
lynx -dump http://www.cotacaodolar.com.br/hoje.html
</pre>

<p>ou ainda, você pode gravar a página toda num arquivo:</p>

<pre>
lynx -dump http://www.cotacaodolar.com.br/hoje.html &gt; cotacao.txt
</pre>

<p>e pronto! mais da metade do caminho já está andada. com o texto na mão, basta um "pipe" e um <code>grep</code> e nosso problema está resolvido:</p>

<pre>
lynx -dump http://www.cotacaodolar.com.br/hoje.html | grep 'paralelo'
</pre>

<p>e temos extraída apenas a linha com as informações desejadas, obtidas fresquinhas direto da internet. percebeu o poder disso? usando o <code>lynx</code> e filtros como <code>grep</code>, <code>sed</code> e <code>awk</code>, pode-se obter automaticamente, QUALQUER dado de QUALQUER página da internet. deixemos os planos de dominação mundial para depois e vamos continuar a estressar o assunto.</p>

<p>suponhamos que você precise baixar a página em HTML mesmo, ou extrair dados que estão "escondidos" nas marcações e atributos de formulários. sem problema, usando o <code>-source</code> baixamos a página "como ela é", igual ao "salvar como" de outros navegadores, ou o <code>wget</code>:</p>

<pre>
lynx -source http://www.cotacaodolar.com.br/hoje.html &gt; dolar.html
</pre>

<p>principalmente os que sofrem com conexões lentas, essa automatização é benéfica e econômica. digamos que você todos os dias acessa dois sites de notícia, um de esportes e um de variedades para ver as novidades do dia. então basta fazer um script rápido onde o <code>lynx</code> baixa todas essas páginas. então você se conecta, roda o script, se desconecta, e pode ler as notícias com calma, sem gastar telefone.</p>

<p>e ainda, um segundo script pode reformatar as páginas, tirando todas as propagandas, alterando fontes e cores, ou seja, uma personalização local da página para que sua leitura fique mais agradável.</p>

<p>mas além de obter, você também pode enviar informações automaticamente (olha lá o que você vai fazer hein?). que tal preencher formulários para várias pessoas obtendo os dados de um banco de dados local e enviá-los para um site qualquer da internet?</p>

<pre>
echo "nome=carlos&amp;idade=33&amp;..." | lynx -post-data http://www.../cadastro.cgi
</pre>

<p>pa bo en me pa ba.</p>

<p>para ver usos práticos do <code>lynx</code> para envio e obtenção automatizada de informações, acesse <a href="https://funcoeszz.net">https://funcoeszz.net</a>, a casa das "funções ZZ", um pacote de funções diversas para bash que usam <code>lynx</code> e <code>sed</code> para obter e formatar informações, fazendo pesquisas na internet em dicionários, tradutores, imposto de renda, cotação do dólar e outros.</p>

<p>além do <code>lynx</code> há outros dois navegadores para modo texto que trazem funcionalidades a mais e dividem a preferência dos usuários: <code>links</code> (<a href="http://artax.karlin.mff.cuni.cz/~mikulas/links">http://artax.karlin.mff.cuni.cz/~mikulas/links</a>) e <code>w3m</code> (<a href="http://ei5nazha.yz.yamagata-u.ac.jp/~aito/w3m/eng">http://ei5nazha.yz.yamagata-u.ac.jp/~aito/w3m/eng</a>), que possuem, entre outros, renderização de cores, tabelas e frames, e abertura de links em outras janelas (use com o <code>screen</code>!). eles também contam com suporte a mouse, com direito a menu de contexto no botão direito (eca!). mas note que o <code>links</code> tem um problema crônico com cookies e autenticação <code>http</code> via proxy.</p>

<p>vida longa aos navegadores em modo texto, pois na busca de informações o que importa é o conteúdo, e não sua apresentação.</p>
